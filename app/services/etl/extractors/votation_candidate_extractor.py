import io
import zipfile
from typing import AsyncGenerator, Optional

import httpx
import pandas as pd
from loguru import logger


class VotationExtractor:
    """Extrator simplificado usando CDN direta do TSE."""

    CDN_TSE_BASE_URL = "https://cdn.tse.jus.br/estatistica/sead/odsele"

    def __init__(self):
        self.http_client = httpx.AsyncClient(timeout=300.0)

    async def close(self):
        """Fecha cliente HTTP."""
        await self.http_client.aclose()

    async def _download_and_extract_csv(
            self,
            url: str,
            expected_csv: str,
            encoding: str = 'latin-1',
            sep: str = ';'
    ) -> AsyncGenerator[pd.DataFrame, None]:
        """
            Baixa um ZIP via HTTP e extrai APENAS o CSV especificado.

            Args:
                url: URL do arquivo ZIP
                expected_csv: Nome exato do CSV a extrair (ex: 'votacao_candidato_munzona_2024_BRASIL.csv')
                encoding: Encoding do CSV (padr√£o: 'latin-1' para TSE)
                sep: Separador do CSV (padr√£o: ';')

            Yields:
                DataFrame do CSV extra√≠do

            Raises:
                HTTPStatusError: Se URL n√£o existir (404, etc)
                ValueError: Se CSV n√£o for encontrado no ZIP
            """
        logger.info(f"Baixando arquivo de {url}")

        try:
            async with self.http_client.stream("GET", url) as response:
                response.raise_for_status()
                content = await response.aread()

            logger.info(f"‚úÖ ZIP baixado: {len(content) / 1024 / 1024:.2f} MB")

            with zipfile.ZipFile(io.BytesIO(content)) as z:
                csv_files = [f for f in z.namelist() if f.endswith('.csv')]
                logger.debug(f"üìÇ CSVs no ZIP: {csv_files}")

                # Verifica se CSV esperado existe
                if expected_csv not in z.namelist():
                    logger.warning(f"‚ö†Ô∏è  CSV '{expected_csv}' n√£o encontrado")
                    logger.info(f"CSVs dispon√≠veis: {csv_files}")

                    # Fallback: usa primeiro CSV se houver
                    if csv_files:
                        expected_csv = csv_files[0]
                        logger.info(f"üìù Usando CSV alternativo: {expected_csv}")
                    else:
                        raise ValueError(
                            f"Nenhum CSV encontrado no ZIP de {url}. "
                            f"Arquivos no ZIP: {z.namelist()}"
                        )

                with z.open(expected_csv) as f:
                    df = pd.read_csv(f, encoding=encoding, sep=sep, dtype=str, low_memory=False)

                logger.info(f"‚úÖ CSV lido: {len(df):,} linhas, {len(df.columns)} colunas")
                yield df

        except httpx.HTTPStatusError as e:
            logger.error(f"‚ùå Erro HTTP {e.response.status_code}: {url}")
            raise ValueError(f"Arquivo n√£o encontrado na CDN: {url} (HTTP {e.response.status_code})")

        except zipfile.BadZipFile:
            logger.error(f"‚ùå Arquivo baixado n√£o √© um ZIP v√°lido: {url}")
            raise ValueError(f"Arquivo corrompido ou n√£o √© ZIP: {url}")

        except Exception as e:
            logger.error(f"‚ùå Erro ao processar ZIP: {e}", exc_info=True)
            raise

    async def extract_votation_year(
            self,
            year: int,
            uf: Optional[str] = None
    ) -> AsyncGenerator[pd.DataFrame, None]:
        """
        Extrai vota√ß√£o por candidato usando CDN direta do TSE.

        Args:
            year: Ano da elei√ß√£o (ex: 2024)
            uf: Sigla da UF para filtrar (opcional)

        Yields:
            DataFrame com dados de vota√ß√£o
        """
        zip_url = f"{self.CDN_TSE_BASE_URL}/votacao_candidato_munzona/votacao_candidato_munzona_{year}.zip"

        if uf:
            expected_csv = f"votacao_candidato_munzona_{year}_{uf.upper()}.csv"
        else:
            expected_csv = f"votacao_candidato_munzona_{year}_BRASIL.csv"

        try:
            async for df in self._download_and_extract_csv(
                    url=zip_url,
                    expected_csv=expected_csv
            ):
                logger.info(f"‚úÖ CSV extra√≠do: {len(df):,} registros")
                yield df
        except ValueError as e:
            logger.error(f"‚ùå Erro na extra√ß√£o: {e}")
            raise